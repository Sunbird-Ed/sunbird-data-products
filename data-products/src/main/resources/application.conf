default.parallelization=10
spark_output_temp_dir="/tmp/"

# the below urls should be https - do not update them
lp.url="https://dev.ekstep.in/api/learning"
lp.path="/api/learning/v2/content/"


# Content to vec configurations
content2vec_scripts_path="../../platform-scripts/python/main/vidyavaani"
pc_files_cache="file"
pc_dispatch_params="""{"bucket":""}"""
pc_files_prefix="/tmp/data-sets/"

metrics.dispatch.to="file"
metrics.dispatch.params="""{"bucket":""}"""
metrics.consumption.dataset.id="/tmp/data-sets/eks-consumption-metrics/"
metrics.creation.dataset.id="/tmp/data-sets/eks-creation-metrics/"

default.consumption.app.id="genie"
default.channel.id="in.sunbird"
default.creation.app.id="portal"

lp.contentmodel.versionkey=jd5ECm/o0BXwQCe8PfZY1NoUkB9HN41QjA80p22MKyRIcP5RW4qHw8sZztCzv87M

reactiveinflux {
  url = "http://localhost:8086/"
  spark {
    batchSize = 1000
  }
  database = "business_metrics_test_db"
  awaitatmost = "60"
}

# Neo4j
neo4j.bolt.url="bolt://localhost:7687"
neo4j.bolt.user="neo4j"
neo4j.bolt.password="@n@lytic5"


# Test Configurations
graph.service.embedded.enable=true
graph.service.embedded.dbpath="/tmp/graph.db/"
graph.content.limit="100"
cassandra.service.embedded.enable=true
cassandra.cql_path="src/main/resources/data.cql"
cassandra.service.embedded.connection.port=9142
cassandra.keyspace_prefix="local_"
cassandra.hierarchy_store_prefix="dev_"

spark.cassandra.connection.host=127.0.0.1

# Slack Configurations
monitor.notification.channel = "testing"
monitor.notification.name = "dp-monitor"
monitor.notification.slack = false

# DataExhaust configuration
data_exhaust {
	save_config {
		save_type="local"
		bucket="ekstep-dev-data-store"
		prefix="/tmp/data-exhaust/"
		public_s3_url="s3://"
		local_path="/tmp/data-exhaust-package/"
	}
	delete_source: "false"
	package.enable: "false"
}

cloud_storage_type="local"

service.search.url="https://dev.open-sunbird.org/api/composite"
service.search.path="/v1/search"

## Reports - Global config
cloud.container.reports="reports"

# course metrics container in azure
es.host="http://localhost"
es.composite.host="localhost"
es.port="9200"
es.scroll.size = 1000
course.metrics.es.alias="cbatchstats"
course.metrics.es.index.cbatchstats.prefix="cbatchstats-"
course.metrics.es.index.cbatch="cbatch"
course.metrics.cassandra.sunbirdKeyspace="sunbird"
course.metrics.cassandra.sunbirdCoursesKeyspace="sunbird_courses"
admin.reports.cloud.container="reports"
# Folder names within container
course.metrics.cloud.objectKey="reports/"
assessment.metrics.cloud.objectKey="assessment-reports/"
admin.metrics.cloud.objectKey="src/test/resources/admin-user-reports/"
admin.metrics.temp.dir="/tmp/admin-user-reports"
# End of report folder names
course.metrics.temp.dir="/tmp/course-reports"
course.metrics.cassandra.input.consistency="QUORUM"
assessment.metrics.temp.dir="/Users/admin/assessment-report"
assessment.metrics.cassandra.input.consistency="QUORUM"
assessment.metrics.content.index="compositesearch"
assessment.metrics.es.alias="cbatch-assessment"
assessment.metrics.es.index.prefix="cbatch-assessment-"
course.upload.reports.enabled=true
course.es.index.enabled=true
assessment.metrics.bestscore.report=true // BestScore or Latst Updated Score	
assessment.metrics.supported.contenttype="SelfAssess"
spark.sql.caseSensitive=true

reports_storage_key=""
reports_storage_secret=""

# content rating configurations
druid.sql.host="http://localhost:8082/druid/v2/sql/"
druid.unique.content.query="{\"query\":\"SELECT DISTINCT \\\"object_id\\\" AS \\\"Id\\\"\\nFROM \\\"druid\\\".\\\"summary-events\\\" WHERE \\\"__time\\\"  BETWEEN TIMESTAMP '%s' AND TIMESTAMP '%s'\"}"
druid.content.rating.query="{\"query\":\"SELECT \\\"object_id\\\" AS contentId, COUNT(*) AS \\\"totalRatingsCount\\\", SUM(edata_rating) AS \\\"Total Ratings\\\", SUM(edata_rating)/COUNT(*) AS \\\"averageRating\\\" FROM \\\"druid\\\".\\\"telemetry-feedback-events\\\" WHERE \\\"eid\\\" = 'FEEDBACK' GROUP BY \\\"object_id\\\"\"}"
lp.system.update.base.url="http://localhost:8080/learning-service/system/v3/content/update"

druid = {
	hosts = "localhost:8082"
	secure = false
	url = "/druid/v2/"
	datasource = "summary-events"
	response-parsing-timeout = 300000
}
druid.query.wait.time.mins=1
druid.report.upload.wait.time.mins=1

#Experiment Configuration
user.search.api.url = "http://localhost:9000/private/user/v1/search"
user.search.limit = 10000

spark.memory_fraction=0.3
spark.storage_fraction=0.5
spark.driver_memory=1g

# pipeline auditing
//druid.pipeline_metrics.audit.query="{\"query\":\"SELECT \\\"job-name\\\", SUM(\\\"success-message-count\\\") AS \\\"success-message-count\\\", SUM(\\\"failed-message-count\\\") AS \\\"failed-message-count\\\", SUM(\\\"duplicate-event-count\\\") AS \\\"duplicate-event-count\\\", SUM(\\\"batch-success-count\\\") AS \\\"batch-success-count\\\", SUM(\\\"batch-error-count\\\") AS \\\"batch-error-count\\\", SUM(\\\"primary-route-success-count\\\") AS \\\"primary-route-success-count\\\", SUM(\\\"secondary-route-success-count\\\") AS \\\"secondary-route-success-count\\\" FROM \\\"druid\\\".\\\"pipeline-metrics\\\" WHERE \\\"job-name\\\" IN (%s) AND \\\"__time\\\" BETWEEN TIMESTAMP '%s' AND TIMESTAMP '%s' GROUP BY \\\"job-name\\\" \"}"
//druid.datasource.count.query="{ \"query\": \"SELECT COUNT(*) AS \\\"total\\\" FROM \\\"druid\\\".\\\"%s\\\" WHERE TIME_FORMAT(MILLIS_TO_TIMESTAMP(\\\"syncts\\\"), 'yyyy-MM-dd HH:mm:ss.SSS', 'Asia/Kolkata') BETWEEN TIMESTAMP '%s' AND '%s' AND  \\\"__time\\\" BETWEEN TIMESTAMP '%s' AND TIMESTAMP '%s'\" }"

//Postgres Config
postgres.db="postgres"
postgres.url="jdbc:postgresql://localhost:65124/"
postgres.user="postgres"
postgres.pass="postgres"
druid.content.consumption.query="{\"query\":\"SELECT COUNT(*) as \\\"play_sessions_count\\\", SUM(total_time_spent) as \\\"total_time_spent\\\", dimensions_pdata_id, object_id\\nFROM \\\"summary-events\\\"\\nWHERE \\\"dimensions_mode\\\" = 'play' AND \\\"dimensions_type\\\" ='content'\\nGROUP BY object_id, dimensions_pdata_id\"}"

// TPD Configurations
org.search.api.url="https://dev.sunbirded.org/api"
org.search.api.path="/org/v1/search"
druid.host="http://localhost:8082/druid/v2"
elasticsearch.index.coursebatch.name="course-batch"
//ETB Configurations
hierarchy.search.api.url="https://dev.sunbirded.org/api/course"
hierarchy.search.api.path="/v1/hierarchy/"

sunbird_encryption_key=""
sunbird_encryption="ON"

dcedialcode.filename="DCE_dialcode_data.csv"
etbdialcode.filename="ETB_dialcode_data.csv"
dcetextbook.filename="DCE_textbook_data.csv"
etbtextbook.filename="ETB_textbook_data.csv"
